{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping project - version 1.01\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import requests                     # For requesting urls\n",
    "from bs4 import BeautifulSoup       # Parsing and handling html files\n",
    "import pandas as pd                 # Structured data frames\n",
    "import numpy as np                  # Support to data frames and used on exceptions np.nan\n",
    "import matplotlib.pyplot as plt     # Visualizations library\n",
    "from collections import OrderedDict # Preserving column order on dictionaries for data frames\n",
    "%matplotlib inline                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format of DataFrame that will be created\n",
    "# Initially built to give me an idea of required attributes \n",
    "\n",
    "df = {'ProductID':[],\n",
    "      'ProductName':[],\n",
    "      'Company':[],\n",
    "      'WhoUses_Description': [],\n",
    "      'TargetCustomerSize' : [],\n",
    "      'StartPrice' : [],\n",
    "      'FreeTrial' : [],\n",
    "      'Features' : [],\n",
    "      'OverallRating':[],\n",
    "      'EaseOfUse':[],\n",
    "      'CustomerService':[],\n",
    "      'Features&Functionalities':[],\n",
    "      'ValueForMoney':[],\n",
    "      'Support':[],\n",
    "      'Training':[]}\n",
    "\n",
    "df = pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Requesting the front page of Capterra website\n",
    "\n",
    "url_frontpage = 'https://www.capterra.com/real-estate-property-management-software/'\n",
    "r = requests.get(url_frontpage)\n",
    "html_doc = r.text\n",
    "r.close()\n",
    "soup = BeautifulSoup(html_doc, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of products listed on url_frontpage requested is 208\n"
     ]
    }
   ],
   "source": [
    "# Grabs a list with each item on url listing: all_items\n",
    "# all_items is the base for the loop on the main code\n",
    "# Prints the amount of entries to be scraped\n",
    "\n",
    "all_items = soup.findAll(\"div\", {'class':'card listing'})\n",
    "print(\"Total amount of products listed on url_frontpage requested is %d\" % len(all_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The code strategy:\n",
    "# The attributes from each product is easier to get from the comparison page from Capterra's website, therefore:\n",
    "#   Creation of an initial array with all product IDs;\n",
    "#   For each pair of product ID we request a new comparison page url, this becomes a loop;\n",
    "#   Attributes from comparison page is mapped and stored in temporary arrays;\n",
    "#   Final arrays are appended with information by pairs, coming from the comparison page;\n",
    "#   Loop of comparison is repeated until the last pair of ID in product ID array.\n",
    "\n",
    "# Opening empty lists to store info arrays \n",
    "\n",
    "IDs = []\n",
    "ProductName = []\n",
    "Company = []\n",
    "WhoUses_Description = []\n",
    "TargetCustomerSize = []\n",
    "OverallRating = []\n",
    "EaseOfUse = []\n",
    "CustomerService = []\n",
    "Features_Functionality = []\n",
    "ValueForMoney = []\n",
    "StartPrice = []\n",
    "FreeTrial = []\n",
    "Deployement = []\n",
    "Support = []\n",
    "Features = []\n",
    "Training = []\n",
    "URL = []\n",
    "\n",
    "# Main code\n",
    "\n",
    "# Changing index changes where the comparison starts on all_items array, with all product IDs\n",
    "# Note that index+=2 indicates the change of comparison pair\n",
    "index = 0 \n",
    "for item in all_items:\n",
    "    item1 = all_items[index]['id']\n",
    "    item2 = all_items[index+1]['id']\n",
    "    index += 2\n",
    "    \n",
    "    # If clause to not break all_items length\n",
    "    if index >= len(all_items):\n",
    "        break\n",
    "        \n",
    "    # Creation of url_compare to enter the comparison page\n",
    "    url_compare = 'https://www.capterra.com/real-estate-property-management-software/compare/' + \\\n",
    "              item1.replace('product-', '') + '-' + item2.replace('product-', '')\n",
    "    r = requests.get(url_compare)\n",
    "    html_doc = r.text\n",
    "    r.close()\n",
    "    soup_compare = BeautifulSoup(html_doc, \"html.parser\")    \n",
    "    \n",
    "    # Appending product IDs\n",
    "    IDs.extend([item1, item2])\n",
    "    \n",
    "    # Appending names of product list 0 and 1 for the items in soup_compare\n",
    "    ProductName.extend([soup_compare.findAll('div', {'class':'stack'})[1]\\\n",
    "    .findAll('a', {'onclick':\"ga('send', 'event', 'Product Compare', 'Product Name Click');\"})[0].text.strip(),\n",
    "                        soup_compare.findAll('div', {'class':'stack'})[1]\\\n",
    "    .findAll('a', {'onclick':\"ga('send', 'event', 'Product Compare', 'Product Name Click');\"})[1].text.strip()])\n",
    "        \n",
    "        \n",
    "    # Appending companies responsable for the product list 0 and 1 for the items in soup_compare\n",
    "    Company.extend([soup_compare.findAll('div', {'class':'stack'})[1]\\\n",
    "    .findAll('p', {'class':\"color-gray no-margin-bottom milli\"})[0].text.replace('by\\n', '').strip(),\n",
    "    soup_compare.findAll('div', {'class':'stack'})[1]\\\n",
    "    .findAll('p', {'class':\"color-gray no-margin-bottom milli\"})[1].text.replace('by\\n', '').strip()])\n",
    "\n",
    "    # Appending who uses this software list 1 and 2 for the items in soup_compare\n",
    "    WhoUses_Description.extend([soup_compare.findAll('div', {'class':'stack'})[2]\n",
    "                               .findAll('td', {'class':'cell-divider'})[1].text,\n",
    "                               soup_compare.findAll('div', {'class':'stack'})[2].\n",
    "                               findAll('td', {'class':'cell-divider'})[2].text]\n",
    "    )\n",
    "    \n",
    "    # Target Customer Size (Users) list 4 and 5 for the items in soup_compare\n",
    "    TargetCustomerSize.extend([soup_compare.findAll('div', {'class':'stack'})[2]\n",
    "                               .findAll('td', {'class':'cell-divider'})[4].text,\n",
    "                              soup_compare.findAll('div', {'class':'stack'})[2]\n",
    "                               .findAll('td', {'class':'cell-divider'})[5].text])\n",
    "    \n",
    "    # Pricing section from 0 to 8\n",
    "    # Used 1-2 (start price) and 4-5 (free trial)\n",
    "    StartPrice.extend([soup_compare.findAll('div', {'class':'stack'})[3]\n",
    "                       .findAll('td', {'class':'cell-divider'})[1].text.strip(),\n",
    "                       soup_compare.findAll('div', {'class':'stack'})[3]\n",
    "                       .findAll('td', {'class':'cell-divider'})[2].text.strip()])\n",
    "    FreeTrial.extend([soup_compare.findAll('div', {'class':'stack'})[3]\n",
    "                       .findAll('td', {'class':'cell-divider'})[4].text.strip(),\n",
    "                       soup_compare.findAll('div', {'class':'stack'})[3]\n",
    "                       .findAll('td', {'class':'cell-divider'})[5].text.strip()])\n",
    "    \n",
    "    # How to handle this exception? The code above is only used if there is a description\n",
    "    # If \"not provided by vendor\" the third findAll is not applicable!\n",
    "    a = soup_compare.findAll('div', {'class':'stack'})[4]\\\n",
    "    .findAll('td', {'class':'cell-divider'})[4]\n",
    "    b = soup_compare.findAll('div', {'class':'stack'})[4]\\\n",
    "    .findAll('td', {'class':'cell-divider'})[5]\n",
    "\n",
    "    if len(a.text.split()) != 4:\n",
    "        a_feature_list = []\n",
    "        for feature in a.select('li[class=ss-check]'):\n",
    "            a_feature_list.append(feature.text.strip())\n",
    "        \n",
    "        Features.append(a_feature_list)\n",
    "    \n",
    "    else:\n",
    "        Features.append(a.text.strip())\n",
    "            \n",
    "    if len(b.text.split()) != 4:\n",
    "        b_feature_list = []\n",
    "        for feature in b.select('li[class=ss-check]'):\n",
    "            b_feature_list.append(feature.text.strip())\n",
    "        \n",
    "        Features.append(b_feature_list)\n",
    "            \n",
    "    else:\n",
    "        Features.append(b.text.strip())\n",
    "            \n",
    "    # Appending Overall Ratings att 1 - 2 on last findAll\n",
    "    # Note that try and except clauses are used to handle missing ratings\n",
    "    try: \n",
    "        OverallRating.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                          .findAll('td', {'class':'cell-divider'})[1].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        OverallRating.append(np.NaN)\n",
    "        \n",
    "    try:    \n",
    "        OverallRating.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                          .findAll('td', {'class':'cell-divider'})[2].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        OverallRating.append(np.NaN)\n",
    "        \n",
    "    # Appending Ratings section Ease to Use att 4 - 5 on last findAll\n",
    "    # Note that try and except clauses are used to handle missing ratings\n",
    "    try:\n",
    "        EaseOfUse.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                      .findAll('td', {'class':'cell-divider'})[4].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        EaseOfUse.append(np.NaN)\n",
    "        \n",
    "    try:\n",
    "        EaseOfUse.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                      .findAll('td', {'class':'cell-divider'})[5].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        EaseOfUse.append(np.NaN)  \n",
    "    \n",
    "    # Appending Ratings section Customer Service att 7 - 8 on last findAll\n",
    "    # Note that try and except clauses are used to handle missing ratings\n",
    "    try:\n",
    "        CustomerService.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                            .findAll('td', {'class':'cell-divider'})[7].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        CustomerService.append(np.NaN)\n",
    "        \n",
    "    try:    \n",
    "        CustomerService.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                            .findAll('td', {'class':'cell-divider'})[8].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        CustomerService.append(np.NaN)\n",
    "    \n",
    "    # Appending Ratings section Features & Functionality att 10 - 11 on last findAll\n",
    "    # Note that try and except clauses are used to handle missing ratings\n",
    "    try:\n",
    "        Features_Functionality.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                                   .findAll('td', {'class':'cell-divider'})[10].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "         Features_Functionality.append(np.NaN)                         \n",
    "    \n",
    "    try:\n",
    "        Features_Functionality.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                                   .findAll('td', {'class':'cell-divider'})[11].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "         Features_Functionality.append(np.NaN)\n",
    "    \n",
    "    # Appending Ratings section ValueForMoney att 13 - 14 on last findAll\n",
    "    # Note that try and except clauses are used to handle missing ratings\n",
    "    \n",
    "    try: \n",
    "        ValueForMoney.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                             .findAll('td', {'class':'cell-divider'})[13].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        ValueForMoney.append(np.NaN)\n",
    "    \n",
    "    try:\n",
    "        ValueForMoney.append(soup_compare.findAll('div', {'class':'stack'})[5]\n",
    "                             .findAll('td', {'class':'cell-divider'})[14].text.strip().split()[0])\n",
    "    except IndexError:\n",
    "        ValueForMoney.append(np.NaN) \n",
    "    \n",
    "    # Solution for feature disable, transform each item on list in string and check if 'feature-disable' in string\n",
    "    # From 1 - 2 \n",
    "    a_sup = soup_compare.findAll('div', {'class':'stack'})[6].findAll('td', {'class':'cell-divider'})[1].findAll('li')\n",
    "    a_sup_list = []\n",
    "    for entry in a_sup:\n",
    "        if 'feature-disable' not in str(entry):\n",
    "            a_sup_list.append(entry.text)\n",
    "    Support.append(a_sup_list)\n",
    "        \n",
    "    b_sup = soup_compare.findAll('div', {'class':'stack'})[6].findAll('td', {'class':'cell-divider'})[2].findAll('li')\n",
    "    b_sup_list = []\n",
    "    for entry in b_sup:\n",
    "        if 'feature-disable' not in str(entry):\n",
    "            b_sup_list.append(entry.text)\n",
    "    Support.append(b_sup_list)\n",
    "    \n",
    "    # Training section 4 - 5 \n",
    "    # Note the special solution of \"class=ss-check\\ \" due to a space after \"check\" \n",
    "    \n",
    "    trainings_a = soup_compare.findAll('div', {'class':'stack'})[6]\\\n",
    "    .findAll('td', {'class':'cell-divider'})[4].select(\"li[class=ss-check\\ ] \")\n",
    "    trainings_b = soup_compare.findAll('div', {'class':'stack'})[6]\\\n",
    "    .findAll('td', {'class':'cell-divider'})[5].select(\"li[class=ss-check\\ ] \")\n",
    "    training_list_a = []\n",
    "    training_list_b = []\n",
    "    \n",
    "    for training in trainings_a:\n",
    "        training_list_a.append(training.text)\n",
    "        \n",
    "    for training in trainings_b:\n",
    "        training_list_b.append(training.text)\n",
    "        \n",
    "    Training.extend([training_list_a, training_list_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the URL to df\n",
    "# This came as an extra task after the main code was done\n",
    "\n",
    "# the code strategy\n",
    "#   I noted that I could extract product's urls from the main front page that means no need to new requests\n",
    "\n",
    "# New array initialized to store scraped info\n",
    "# item.a['href'] was the pattern to get desider urls\n",
    "URL = []\n",
    "\n",
    "for item in all_items[0:206]:\n",
    "    URL.append('https://www.capterra.com/' + item.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary done using the information arrays\n",
    "# Note the OrderedDict used here to keep column orders when parsing to Excel file\n",
    "df =OrderedDict({'ProductID':IDs,\n",
    "      'ProductName':ProductName,\n",
    "      'Product URL': URL,\n",
    "      'Company':Company,\n",
    "      'WhoUses_Description': WhoUses_Description,\n",
    "      'TargetCustomerSize' : TargetCustomerSize,\n",
    "      'StartPrice' : StartPrice,\n",
    "      'FreeTrial' : FreeTrial,\n",
    "      'Features' : Features,\n",
    "      'OverallRating':OverallRating,\n",
    "      'EaseOfUse':EaseOfUse,\n",
    "      'CustomerService':CustomerService,\n",
    "      'Features&Functionality' : Features_Functionality,\n",
    "      'ValueForMoney': ValueForMoney,\n",
    "      'Support':Support,\n",
    "      'Training': Training})\n",
    "\n",
    "df = pd.DataFrame.from_dict(df)\n",
    "\n",
    "# Saving in csv\n",
    "df.to_csv(str(soup.title.text) + '.csv', header=df.columns, sep=',', encoding='utf-8')\n",
    "\n",
    "#Saving in excel\n",
    "writer = pd.ExcelWriter((soup.title.text) + '.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below this point is every prototyping step I used to map every attribute from the scraped page, I decided to keep it messy to remember my reasoning and for self learning purposes.\n",
    "\n",
    "### Questions and suggestions are more than welcome\n",
    "### https://www.linkedin.com/in/joaoostrowski/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Appending Ratings section Features & Functionality att 10 - 11 on last findAll\n",
    "#soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[10].text.strip().split()[0]\n",
    "#soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[11].text.strip().split()[0]\n",
    "    \n",
    "# Appending Ratings section ValueForMoney att 13 - 14 on last findAll\n",
    "\n",
    "try:\n",
    "    soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[13].text.strip().split()[0]\n",
    "except IndexError:\n",
    "    print('ok')\n",
    "#soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[14].text.strip().split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product-167973', 'product-165852', 'product-38478', 'product-133029']"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop generating list of IDs: id_list\n",
    "\n",
    "id_list = []\n",
    "for product in all_items:\n",
    "    id_list.append(product['id'])\n",
    "    \n",
    "id_list[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the url for compasion betwwen product on id_list\n",
    "\n",
    "url_compare = 'https://www.capterra.com/real-estate-property-management-software/compare/' + \\\n",
    "              id_list[2].replace('product-', '') + '-' + id_list[3].replace('product-', '')\n",
    "r = requests.get(url_compare)\n",
    "html_doc = r.text\n",
    "r.close()\n",
    "soup_compare = BeautifulSoup(html_doc, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates the right list with \n",
    "# Name of product, Product's company, Rating, Number of Ratings\n",
    "def string_transform(self):\n",
    "    new_string = self.text.replace('\\n', '').replace('Remove', '').replace('/', '').replace('by', '').split()\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#soup_compare.findAll('th', {'class':'cell-divider'})[1].text\n",
    "\n",
    "#print(string_transform(soup_compare.findAll('th', {'class':'cell-divider'})[1]))\n",
    "#print(string_transform(soup_compare.findAll('th', {'class':'cell-divider'})[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup_compare.findAll('th', {'class':'cell-divider'})[2].text.replace('\\n', '').replace('Remove', '')\\\n",
    "    #.replace('/', '').replace('by', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LiveTour'"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I found the sintax of the blocks\n",
    "# The first findAll I run from block to block (i.e Best For - Pricing...)\n",
    "\n",
    "# Name of product list 0 and 1 for the items in soup_compare\n",
    "soup_compare.findAll('div', {'class':'stack'})[1]\\\n",
    "    .findAll('a', {'onclick':\"ga('send', 'event', 'Product Compare', 'Product Name Click');\"})[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TOPS Software'"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I found the sintax of the blocks\n",
    "# The first findAll I run from block to block (i.e Best For - Pricing...)\n",
    "\n",
    "# Company responsable for the product list 0 and 1 for the items in soup_compare\n",
    "soup_compare.findAll('div', {'class':'stack'})[1]\\\n",
    "    .findAll('p', {'class':\"color-gray no-margin-bottom milli\"})[1].text.replace('by\\n', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ShowingHero is a online software for Property Managers by Property Managers. We love to work with technology driven and forward thinking organizations who are looking to simplify the leasing process'"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I found the sintax of the blocks\n",
    "# The first findAll I run from block to block (i.e Best For - Pricing...)\n",
    "# The second findAll I run from cel to cell (i.e inside of 'Best For: Who Uses This Software? - Real state agents...)\n",
    "\n",
    "# Who uses this software list 1 and 2 for the items in soup_compare\n",
    "soup_compare.findAll('div', {'class':'stack'})[2].findAll('td', {'class':'cell-divider'})[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 - 1000+'"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Customer Size (Users) list 4 and 5 for the items in soup_compare\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[2].findAll('td', {'class':'cell-divider'})[4].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pricing section from 0 to 8\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[3].findAll('td', {'class':'cell-divider'})[8].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not provided by vendor'"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Platform section\n",
    "\n",
    "#Works but not properly\n",
    "#soup_compare.findAll('div', {'class':'stack'})[4].findAll('td', {'class':'cell-divider'})[4].findAll('li', {'class':'ss-check'})\n",
    "\n",
    "# Further test\n",
    "# Works the same as the one below but worse coding\n",
    "#soup_compare.findAll('div', {'class':'stack'})[4].findAll('td', {'class':'cell-divider'})[4].findAll(lambda tag: tag.name ==\n",
    "                                                                                                #     'li' and tag.get('class')\n",
    "                                                                                                 #    == ['ss-check'])[0]\n",
    "                                                                                                \n",
    "# Works amazingly\n",
    "soup_compare.findAll('div', {'class':'stack'})[4].findAll('td', {'class':'cell-divider'})[5].text.strip()\n",
    "\n",
    "#[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Residential Properties'"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to handle this exception? The code above is only used if there is a description\n",
    "# If \"not provided by vendor\" the third findAll is not applicable!\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[4].findAll('td', {'class':'cell-divider'})[4].select('li[class=ss-check]')[1]\\\n",
    "    .text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings section Ease to Use att 4 - 5 on last findAll\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[4].text.strip().split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings section Customer Service att 7 - 8 on last findAll\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[7].text.strip().split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings section Features & Functionality att 10 - 11 on last findAll\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[10].text.strip().split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5'"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings section Value for Money att 13 - 14 on last findAll\n",
    "\n",
    "soup_compare.findAll('div', {'class':'stack'})[5].findAll('td', {'class':'cell-divider'})[13].text.strip().split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li class=\"ss-user feature-disabled\">24/7 (Live Rep)</li>,\n <li class=\"ss-clock \">Business Hours</li>,\n <li class=\"ss-laptop \">Online</li>]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings section Customer Service att 7 - 8 on last findAll\n",
    "\n",
    "# Works with the feature disable problem\n",
    "soup_compare.findAll('div', {'class':'stack'})[6].findAll('td', {'class':'cell-divider'})[1].findAll('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Hours\nOnline\n"
     ]
    }
   ],
   "source": [
    "# Solution for feature disable, tranform each item on list in string and check if 'feature-disable' in string\n",
    "# From 1 - 2 \n",
    "\n",
    "a = soup_compare.findAll('div', {'class':'stack'})[6].findAll('td', {'class':'cell-divider'})[1].findAll('li')\n",
    "for entry in a:\n",
    "    if 'feature-disable' in str(entry):\n",
    "        pass\n",
    "    else:\n",
    "        print(entry.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training section 4 - 5 \n",
    "# Note the special solution of \"class=ss-check\\ \" due to a space after \"check\" \n",
    "\n",
    "len(soup_compare.findAll('div', {'class':'stack'})[6].findAll('td', {'class':'cell-divider'})[4].select(\"li[class=ss-check\\ ] \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
